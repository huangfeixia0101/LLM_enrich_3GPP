"æ¢¯åº¦è®­ç»ƒ"
# L=(wx-y)^2
# dL/dW= d(wx-y)^2/d(wx-y)*d(wx-y)/dw
# import torch
#
# # å‡è®¾æˆ‘ä»¬è¦æ‹Ÿåˆ y = 2x çš„å…³ç³»
# x = torch.tensor([1.0, 2.0, 3.0])
# y_true = torch.tensor([2.0, 4.0, 6.0])
#
# # åˆå§‹åŒ–å‚æ•° wï¼ˆæƒé‡ï¼‰
# w = torch.tensor(3.0, requires_grad=True)
#
# learning_rate = 0.1
#
# for epoch in range(10):
#     # å‰å‘ä¼ æ’­
#     y_pred = w * x
#     loss = ((y_pred - y_true)**2).mean()
#
#     # åå‘ä¼ æ’­
#     loss.backward()
#
#     # æ‰‹åŠ¨æ›´æ–°å‚æ•°
#     with torch.no_grad():
#         w -= learning_rate * w.grad
#
#     # æ¸…é›¶æ¢¯åº¦ï¼ˆå¦åˆ™ä¸‹ä¸€è½®ä¼šç´¯åŠ ï¼‰
#     w.grad.zero_()
#
#     print(f"Epoch {epoch}: w = {w.item():.4f}, loss = {loss.item():.4f}ï¼Œ wgrad= {w.grad}")

# ç¥ç»ç½‘ç»œæœ€ç®€å•çš„ PyTorch ç¤ºä¾‹ï¼Œè®­ç»ƒä¸€ä¸ªåŒ…å«çº¿æ€§å±‚ + ReLUæ¿€æ´»çš„å°ç½‘ç»œï¼Œå»æ‹Ÿåˆå‡½æ•°
# ğ‘¦
# =
# 2
# ğ‘¥
# +
# 3
# # y=2x+3ã€‚
# import torch
# import torch.nn as nn
# import torch.optim as optim
#
# # 1. å‡†å¤‡è®­ç»ƒæ•°æ® (x, y = 2x + 3)
# x_train = torch.tensor([[1.0], [2.0], [3.0], [4.0]])
# y_train = 2 * x_train + 3
#
# # å‡è®¾çš„éªŒè¯é›†ï¼ˆç®€å•æ¨¡æ‹Ÿï¼‰
# x_val = torch.tensor([[5.0], [6.0]])
# y_val = 2 * x_val + 3
#
# # 2. å®šä¹‰ç½‘ç»œç»“æ„
# class SimpleNet(nn.Module):
#     def __init__(self):
#         super(SimpleNet, self).__init__()
#         self.linear = nn.Linear(1, 1)  # è¾“å…¥1ç»´ï¼Œè¾“å‡º1ç»´
#
#     def forward(self, x):
#         x = self.linear(x)
#         x = torch.relu(x)  # æ¿€æ´»å‡½æ•°
#         return x
#
# # åˆ›å»ºæ¨¡å‹
# model = SimpleNet()
#
# # 3. æŸå¤±å‡½æ•° & ä¼˜åŒ–å™¨
# criterion = nn.MSELoss()
# optimizer = optim.SGD(model.parameters(), lr=0.1)
#
# # 4. è®­ç»ƒè¿‡ç¨‹
# for epoch in range(300):
#     model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
#     optimizer.zero_grad()
#     outputs = model(x_train)
#     loss = criterion(outputs, y_train)
#     loss.backward()
#     optimizer.step()
#
#     if (epoch + 1) % 50 == 0:
#         print(f"[è®­ç»ƒ] Epoch {epoch + 1}: loss={loss.item():.4f}")
#         for name, param in model.named_parameters():
#             print(f"  {name} = {param.data.item():.4f}")
#
# # 5. è¯„ä¼°é˜¶æ®µï¼ˆéªŒè¯é›†ï¼‰
# model.eval()
# with torch.no_grad():
#     val_outputs = model(x_val)
#     val_loss = criterion(val_outputs, y_val)
#     print(f"\n[éªŒè¯] éªŒè¯é›† loss: {val_loss.item():.4f}")
#     for i in range(len(x_val)):
#         print(f"  è¾“å…¥ {x_val[i].item()} -> é¢„æµ‹å€¼: {val_outputs[i].item():.4f}ï¼ŒçœŸå®å€¼: {y_val[i].item()}")
#
# # 6. ä¿å­˜æ¨¡å‹
# torch.save(model.state_dict(), "simple_model.pth")
# print("\nâœ… æ¨¡å‹å·²ä¿å­˜ä¸º simple_model.pth")
#
# # 7. åŠ è½½æ¨¡å‹å¹¶é¢„æµ‹æ–°çš„è¾“å…¥
# new_model = SimpleNet()
# new_model.load_state_dict(torch.load("simple_model.pth"))
# new_model.eval()
#
# with torch.no_grad():
#     test_input = torch.tensor([[8.0]])
#     pred = new_model(test_input)
#     print(f"\nğŸ§ª é¢„æµ‹è¾“å…¥8æ—¶çš„è¾“å‡º: {pred.item():.4f}")




# å¤šå¤´attention
import torch
import torch.nn.functional as F

# å‡è®¾è¾“å…¥ token æ•°é‡ seq_len=2ï¼Œembeddingç»´åº¦ d_model=8ï¼Œå¤´æ•° h=2
seq_len = 2
d_model = 8
num_heads = 2
d_head = d_model // num_heads  # æ¯ä¸ªå¤´çš„ç»´åº¦

# è¾“å…¥ï¼š2ä¸ªtokenï¼Œæ¯ä¸ª8ç»´
x = torch.randn(seq_len, d_model)  # shape: (2, 8)

# çº¿æ€§å˜æ¢å¾—åˆ° Q, K, Vï¼Œå‡è®¾æƒé‡éƒ½ç”¨å•ä½çŸ©é˜µæ–¹ä¾¿ç†è§£ï¼ˆè¿™é‡Œç›´æ¥ç”¨xï¼‰
Q = x.clone()
K = x.clone()
V = x.clone()

# æ‹†åˆ†ä¸ºå¤šä¸ªå¤´
# æŠŠembeddingç»´åº¦æ‹†æˆå¤´æ•°ä»½ï¼Œæ¯ä»½ç»´åº¦æ˜¯d_head
Q_heads = Q.view(seq_len, num_heads, d_head)  # (2, 2, 4)
K_heads = K.view(seq_len, num_heads, d_head)
V_heads = V.view(seq_len, num_heads, d_head)

print("Q_heads shape:", Q_heads.shape)  # (2 tokens, 2 heads, 4 dims per head)

# è®¡ç®—æ¯ä¸ªå¤´çš„æ³¨æ„åŠ›ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸åšç¼©æ”¾å’Œsoftmaxï¼‰
attn_scores = torch.einsum('thd,Thd->htT', Q_heads, K_heads)
# è§£é‡Šï¼št=tokenï¼Œh=headï¼Œd=dimï¼Œè¾“å‡ºå½¢çŠ¶(å¤´æ•°, æŸ¥è¯¢token, å…³é”®token)
print("attn_scores shape:", attn_scores.shape)

# å¯¹VåŠ æƒæ±‚å’Œï¼ˆç®€åŒ–æ¼”ç¤ºï¼Œå‡è®¾æƒé‡ä¸ºå…¨1ï¼‰
output_heads = V_heads  # å‡è®¾æƒé‡ä¸º1ï¼Œç›´æ¥ç”¨V
print("output_heads shape:", output_heads.shape)

# åˆå¹¶æ‰€æœ‰å¤´çš„è¾“å‡ºï¼Œæ‹¼æ¥æœ€åä¸€ç»´
output_concat = output_heads.reshape(seq_len, d_model)
print("æ‹¼æ¥å output_concat å½¢çŠ¶:", output_concat.shape)
